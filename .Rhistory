rbga.results <- rbga.bin(size = 7, popSize = 200, iters = iter, mutationChance = 0.01, elitism = T, evalFunc = evalFunc)
cat(summary(rbga.results))
source("https://bioconductor.org/biocLite.R")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install(version = "3.60")
BiocManager::install()
str(Titanic)
df <- as.data.frame(Titanic)
head(df)
install.packages('arules')
# Ubah data hasil tabulasi menjadi per penumpang
## Ambil kolom selain "Freq"
cols <- colnames(df)[! colnames(df) %in% "Freq"]
titanic <- sapply(cols,
function(col) {
## Replikasi masing-masing nilai sebanyak "Freq"
rep(df[, col], df$Freq)
})
# Ubah matrix data menjadi data.frame
titanic <- as.data.frame(titanic)
# Ringkasan statistik
summary(titanic)
library(arules)
rules <- apriori(titanic)
# Urutkan rules berdasarkan "lift"
rules <- sort(rules, by="lift")
# Lihat 10 rules terbaik yang terbentuk
inspect(rules[1:10])
# Parameter yang akan diterapkan
params = list(minlen = 2,
support = 0.005,
confidence = 0.8)
# Terapkan algoritme
rules <- apriori(titanic, parameter = params)
rules <- apriori(titanic,
parameter = params,
appearance = list(rhs = c('Survived=Yes'),
default = 'lhs'))
# Urutkan rules berdasarkan "lift"
rules <- sort(rules, by='lift')
# Lihat rules yang terbentuk
inspect(rules)
# Membentuk matriks hubungan subset
subset_matrix <- is.subset(rules, rules)
subset_matrix[lower.tri(subset_matrix)] <- FALSE
# Menentukan rules yang redundan
redundant <- colSums(subset_matrix) > 1
# Untuk melihat rules yang redundan: > which(redundant)
# Ambil rules yang tidak redundan
rules_pruned <- rules[!redundant]
inspect(rules_pruned)
install.packages('arulesViz')
plot(rules_pruned)
# Muat pustaka
# install.packages('arulesViz')
library(arulesViz)
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
library(rlang)
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
# Muat pustaka
# install.packages('arulesViz')
library(arulesViz)
plot(rules_pruned)
remove.packages("rlang", lib="~/R/win-library/3.6")
install.packages("rlang")
install.packages("rlang")
# Muat pustaka
# install.packages('arulesViz')
library(arulesViz)
plot(rules_pruned)
str(Titanic)
df <- as.data.frame(Titanic)
head(df)
# Ubah data hasil tabulasi menjadi per penumpang
## Ambil kolom selain "Freq"
cols <- colnames(df)[! colnames(df) %in% "Freq"]
titanic <- sapply(cols,
function(col) {
## Replikasi masing-masing nilai sebanyak "Freq"
rep(df[, col], df$Freq)
})
# Ubah matrix data menjadi data.frame
titanic <- as.data.frame(titanic)
# Ringkasan statistik
summary(titanic)
# Parameter yang akan diterapkan
params = list(minlen = 2,
support = 0.005,
confidence = 0.8)
rules <- apriori(titanic,
parameter = params,
appearance = list(rhs = c('Survived=Yes'),
default = 'lhs'))
# Urutkan rules berdasarkan "lift"
rules <- sort(rules, by='lift')
library(arules)
rules <- apriori(titanic)
# Urutkan rules berdasarkan "lift"
rules <- sort(rules, by="lift")
str(Titanic)
df <- as.data.frame(Titanic)
head(df)
# Ubah data hasil tabulasi menjadi per penumpang
## Ambil kolom selain "Freq"
cols <- colnames(df)[! colnames(df) %in% "Freq"]
titanic <- sapply(cols,
function(col) {
## Replikasi masing-masing nilai sebanyak "Freq"
rep(df[, col], df$Freq)
})
# Ubah matrix data menjadi data.frame
titanic <- as.data.frame(titanic)
# Ringkasan statistik
summary(titanic)
library(arules)
rules <- apriori(titanic)
unloadNamespace("arules")
unloadNamespace("arulesViz")
update.packages("arules")
library(arules)
# Muat pustaka
# install.packages('arulesViz')
library(arulesViz)
str(Titanic)
df <- as.data.frame(Titanic)
head(df)
# Ubah data hasil tabulasi menjadi per penumpang
## Ambil kolom selain "Freq"
cols <- colnames(df)[! colnames(df) %in% "Freq"]
titanic <- sapply(cols,
function(col) {
## Replikasi masing-masing nilai sebanyak "Freq"
rep(df[, col], df$Freq)
})
# Ubah matrix data menjadi data.frame
titanic <- as.data.frame(titanic)
# Ringkasan statistik
summary(titanic)
library(arules)
rules <- apriori(titanic)
# Urutkan rules berdasarkan "lift"
rules <- sort(rules, by="lift")
# Lihat 10 rules terbaik yang terbentuk
inspect(rules[1:10])
library(devtools)
devtools::install_github("lchiffon/wordcloud2")
library(dplyr)
library(tidytext)
library(wordcloud)
library(wordcloud2)
# Create word-frequency table for wordcloud
df <- read.csv('./data/dataset_fix.csv', stringsAsFactors = F)
setwd("D:/_Kuliah/3_Junior/KOM332 Daming/daming-projek")
# Create word-frequency table for wordcloud
df <- read.csv('./data/dataset_fix.csv', stringsAsFactors = F)
View(df)
text <- df[, c(1,6)]
# Create Word Frequencies
word_frequencies <- text %>%
unnest_tokens(input = pre_processed_text, output = word) %>%
count(word)
word_frequencies
set.seed(123) # for reproducibility
wordcloud(words = word_frequencies$word, freq = word_frequencies$n, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35, colors=brewer.pal(8, "Dark2"))
set.seed(123)
wordcloud2(word_frequencies, figPath = "visualization/garuda.png", size = 1.5,color = "red")
word_frequencies
word_frequencies %>%
arrange(desc(n))
# Create Word Frequencies
word_frequencies <- text %>%
unnest_tokens(input = pre_processed_text, output = word) %>%
count(word) %>%
arrange(desc(n))
word_frequencies[1:200]
word_frequencies[1:200, ]
for_wordcloud2 <- word_frequencies[1:200, ]
set.seed(123)
wordcloud2(for_wordcloud2, figPath = "visualization/garuda.png", size = 1.5,color = "red")
set.seed(123)
wordcloud2(word_frequencies, figPath = "visualization/garuda.png", size = 1.5,color = "red")
set.seed(123)
letterCloud(word_frequencies, word = "Indonesia")
# Create Word Frequencies
word_frequencies <- text %>%
unnest_tokens(input = pre_processed_text, output = word) %>%
count(word)
set.seed(123)
wordcloud2(word_frequencies, figPath = "visualization/garuda.png", size = 1.5,color = "red")
set.seed(123)
wordcloud2(word_frequencies, figPath = "visualization/virus.png", size = 1.5,color = "red")
set.seed(123)
letterCloud(word_frequencies, word = "IPB")
set.seed(123)
wordcloud2(word_frequencies, size = 1.6)
set.seed(123)
wordcloud2(word_frequencies, figPath = "visualization/IPB.png", size = 1.5, color = "blue")
set.seed(123)
wordcloud2(word_frequencies, figPath = "visualization/IPBBW.png", size = 1.5, color = "blue")
wordcloud2(word_frequencies, figPath = "visualization/IPBBW.png", size = 1.5, color = "blue")
word_frequencies[1:20,]
word_sort <- word_frequencies %>%
arrange(desc(n))
word_sort[1:20]
word_frequencies %>%
arrange(desc(n))
word_frequencies %>%
arrange(desc(n)) %>%
top_n(25)
top25 <- word_frequencies %>%
arrange(desc(n)) %>%
top_n(25)
top25
View(top25)
top25 <- word_frequencies %>%
arrange(desc(n)) %>%
top_n(28)
View(top25)
one_gram_freq <- word_frequencies %>%
arrange(desc(word))
one_gram_freq
one_gram_freq <- word_frequencies %>%
arrange(desc(n))
one_gram_freq
library(ggplot2)
one_gram_freq[1:10,]
ggplot(one_gram_freq[1:10,], aes(x=word, y=n)) +
geom_bar()
ggplot(one_gram_freq[1:10,], aes(x=word, y=n)) +
geom_bar(stat = "count")
ggplot(one_gram_freq[1:10,]) +
geom_bar(aes(x=word, y=n))
ggplot(one_gram_freq[1:10,], aes(word, n))
ggplot(one_gram_freq[1:10,], aes(word, n)) +
geom_bar()
rlang::last_error()
str(one_gram_freq)
ggplot(one_gram_freq[1:10,], aes(word, n)) +
geom_bar(stat = "identity")
ggplot(one_gram_freq[1:10,] %>% arrange(word), aes(word, n)) +
geom_bar(stat = "identity")
one_gram_freq
one_gram_freq <- word_frequencies %>%
arrange(desc(n)) %>%
top_n(25)
one_gram_freq
one_gram_freq <- word_frequencies %>%
arrange(desc(n)) %>%
top_n(25) %>%
arrange(word)
one_gram_freq
one_gram_freq <- word_frequencies %>%
arrange(desc(n)) %>%
top_n(25)
one_gram_freq
one_gram_freq <- word_frequencies %>%
arrange(desc(n)) %>%
top_n(25)
ggplot(one_gram_freq, aes(word, n)) +
geom_bar(stat = "identity")
ggplot(one_gram_freq, aes(word, n)) +
geom_bar(stat = "identity") +
coord_flip()
ggplot(one_gram_freq, aes(n, word)) +
geom_bar(stat = "identity") +
coord_flip()
ggplot(one_gram_freq, aes(word, n)) +
geom_bar(stat = "identity") +
coord_flip()
one_gram_freq
one_gram_freq <- word_frequencies %>%
arrange(desc(n)) %>%
top_n(25) %>%
mutate(word2=reorder(word2, n))
one_gram_freq <- word_frequencies %>%
arrange(desc(n)) %>%
top_n(25) %>%
mutate(word2 = reorder(word2, n))
one_gram_freq <- word_frequencies %>%
arrange(desc(n)) %>%
head(25) %>%
mutate(word2 = reorder(word2, n))
one_gram_freq <- word_frequencies %>%
arrange(desc(n)) %>%
head(25) %>%
mutate(word = reorder(word, n))
ggplot(one_gram_freq, aes(word, n)) +
geom_bar(stat = "identity") +
coord_flip()
ggplot(one_gram_freq, aes(word, n)) +
geom_bar(stat = "identity", fill="light blue") +
coord_flip()
ggplot(one_gram_freq, aes(word, n)) +
geom_bar(stat = "identity", fill="cyan") +
coord_flip()
ggplot(one_gram_freq, aes(word, n)) +
geom_bar(stat = "identity", fill="blue") +
coord_flip()
ggplot(one_gram_freq, aes(word, n)) +
geom_bar(stat = "identity", fill="dark blue") +
coord_flip()
# 2-gram frequency
two_gram_freq <- text %>%
unnest_tokens(input = pre_processed_text, output = 2-gram, token = "ngrams", n = 2) %>%
arrange(desc(n)) %>%
head(25) %>%
mutate(2-gram = reorder(2-gram, n)) %>%
ggplot(aes(word, n)) +
geom_bar(stat="identity", fill="orange") +
coord_flip()
# 2-gram frequency
two_gram_freq <- text %>%
unnest_tokens(input = pre_processed_text, output = 2-gram, token = "ngrams", n = 2) %>%
arrange(desc(n)) %>%
head(25) %>%
mutate(2-gram = reorder(2-gram, n)) %>%
ggplot(aes(2-gram, n)) +
geom_bar(stat="identity", fill="orange") +
coord_flip()
# 2-gram frequency
two_gram_freq <- text %>%
unnest_tokens(input = pre_processed_text, output = digram, token = "ngrams", n = 2) %>%
arrange(desc(n)) %>%
head(25) %>%
mutate(digram = reorder(digram, n)) %>%
ggplot(aes(digram, n)) +
geom_bar(stat="identity", fill="orange") +
coord_flip()
two_gram_freq <- text %>%
unnest_tokens(input = pre_processed_text, output = digram, token = "ngrams", n = 2) %>%
arrange(desc(n))
two_gram_freq <- text %>%
unnest_tokens(input = pre_processed_text, output = digram, token = "ngrams", n = 2)
two_gram_freq
head(two_gram_freq)
text %>%
unnest_tokens(input = pre_processed_text, output = digram, token = "ngrams", n = 2) %>%
arrange(desc(X))
# 2-gram frequency
two_gram_freq <- text %>%
unnest_tokens(input = pre_processed_text, output = digram, token = "ngrams", n = 2) %>%
arrange(desc(X)) %>%
head(25) %>%
mutate(digram = reorder(digram, X)) %>%
ggplot(aes(digram, X)) +
geom_bar(stat="identity", fill="orange") +
coord_flip()
two_gram_freq
text %>%
unnest_tokens(input = pre_processed_text, output = digram, token = "ngrams", n = 2) %>%
count(digram, sort = T)
# 2-gram frequency
two_gram_freq <- text %>%
unnest_tokens(input = pre_processed_text, output = digram, token = "ngrams", n = 2) %>%
count(digram, sort = T) %>%
head(25) %>%
mutate(digram = reorder(digram, X))
# 2-gram frequency
two_gram_freq <- text %>%
unnest_tokens(input = pre_processed_text, output = digram, token = "ngrams", n = 2) %>%
count(digram, sort = T) %>%
head(25)
two_gram_freq
ggplot(aes(digram, X)) +
geom_bar(stat="identity", fill="orange") +
coord_flip()
ggplot(aes(digram, N)) +
geom_bar(stat="identity", fill="orange") +
coord_flip()
ggplot(aes(digram, n)) +
geom_bar(stat="identity", fill="orange") +
coord_flip()
ggplot(two_gram_freq, aes(digram, n)) +
geom_bar(stat="identity", fill="orange") +
coord_flip()
# 2-gram frequency
two_gram_freq <- text %>%
unnest_tokens(input = pre_processed_text, output = digram, token = "ngrams", n = 2) %>%
count(digram, sort = T) %>%
head(25) %>%
mutate(word = reorder(word, n))
# 2-gram frequency
two_gram_freq <- text %>%
unnest_tokens(input = pre_processed_text, output = digram, token = "ngrams", n = 2) %>%
count(digram, sort = T) %>%
head(25) %>%
mutate(digram = reorder(digram, n))
ggplot(two_gram_freq, aes(digram, n)) +
geom_bar(stat="identity", fill="orange") +
coord_flip()
# 3-gram frequency
two_gram_freq <- text %>%
unnest_tokens(input = pre_processed_text, output = trigram, token = "ngrams", n = 3) %>%
count(trigram, sort = T) %>%
head(25) %>%
mutate(trigram = reorder(trigram, n))
# 3-gram frequency
trigram_freq <- text %>%
unnest_tokens(input = pre_processed_text, output = trigram, token = "ngrams", n = 3) %>%
count(trigram, sort = T) %>%
head(25) %>%
mutate(trigram = reorder(trigram, n))
ggplot(trigram_freq, aes(digram, n)) +
geom_bar(stat="identity", fill="orange") +
coord_flip()
ggplot(trigram_freq, aes(trigram, n)) +
geom_bar(stat="identity", fill="orange") +
coord_flip()
ggplot(trigram_freq, aes(trigram, n)) +
geom_bar(stat="identity", fill="light green") +
coord_flip()
ggplot(trigram_freq[2:25], aes(trigram, n)) +
geom_bar(stat="identity", fill="light green") +
coord_flip()
ggplot(trigram_freq[2:25,], aes(trigram, n)) +
geom_bar(stat="identity", fill="light green") +
coord_flip()
ggplot(two_gram_freq, aes(digram, n)) +
geom_bar(stat="identity", fill="orange") +
coord_flip()
# 2-gram frequency
two_gram_freq <- text %>%
unnest_tokens(input = pre_processed_text, output = digram, token = "ngrams", n = 2) %>%
count(digram, sort = T) %>%
head(25) %>%
mutate(digram = reorder(digram, n))
ggplot(two_gram_freq, aes(digram, n)) +
geom_bar(stat="identity", fill="orange") +
coord_flip()
ggplot(two_gram_freq[2:25], aes(digram, n)) +
geom_bar(stat="identity", fill="orange") +
coord_flip()
ggplot(two_gram_freq[2:25, ], aes(digram, n)) +
geom_bar(stat="identity", fill="orange") +
coord_flip()
# 2-gram frequency
two_gram_freq <- text %>%
unnest_tokens(input = pre_processed_text, output = digram, token = "ngrams", n = 2) %>%
count(digram, sort = T) %>%
head(25) %>%
mutate(digram = reorder(digram, n))
# 2-gram frequency
two_gram_freq <- text %>%
unnest_tokens(input = pre_processed_text, output = digram, token = "ngrams", n = 2) %>%
count(digram, sort = T) %>%
head(25) %>%
mutate(digram = reorder(digram, n)) %>%
filter(digram != NA)
ggplot(two_gram_freq[2:25, ], aes(digram, n)) +
geom_bar(stat="identity", fill="orange") +
coord_flip()
# 2-gram frequency
two_gram_freq <- text %>%
unnest_tokens(input = pre_processed_text, output = digram, token = "ngrams", n = 2) %>%
count(digram, sort = T) %>%
head(25) %>%
mutate(digram = reorder(digram, n))
two_gram_freq
ggplot(two_gram_freq[2:25, ], aes(digram, n)) +
geom_bar(stat="identity", fill="orange") +
coord_flip()
ggplot(two_gram_freq[-7, ], aes(digram, n)) +
geom_bar(stat="identity", fill="orange") +
coord_flip()
ggplot(trigram_freq[2:25,], aes(trigram, n)) +
geom_bar(stat="identity", fill="light green") +
coord_flip()
ggplot(one_gram_freq, aes(word, n)) +
geom_bar(stat = "identity", fill="dark blue") +
coord_flip()
# Create Word Frequencies
word_frequencies <- text %>%
unnest_tokens(input = pre_processed_text, output = unigram) %>%
count(word)
# Create Word Frequencies
word_frequencies <- text %>%
unnest_tokens(input = pre_processed_text, output = unigram) %>%
count(unigram)
# EDA
# 1-gram frequency
one_gram_freq <- word_frequencies %>%
arrange(desc(n)) %>%
head(25) %>%
mutate(word = reorder(word, n))
# EDA
# 1-gram frequency
one_gram_freq <- word_frequencies %>%
arrange(desc(n)) %>%
head(25) %>%
mutate(unigram = reorder(unigram, n))
ggplot(one_gram_freq, aes(word, n)) +
geom_bar(stat = "identity", fill="dark blue") +
coord_flip()
ggplot(one_gram_freq, aes(unigram, n)) +
geom_bar(stat = "identity", fill="dark blue") +
coord_flip()
ggplot(one_gram_freq, aes(unigram, n)) +
geom_bar(stat = "identity", fill="dark blue") +
coord_flip()
ggplot(two_gram_freq[-7, ], aes(digram, n)) +
geom_bar(stat="identity", fill="orange") +
coord_flip()
ggplot(trigram_freq[2:25,], aes(trigram, n)) +
geom_bar(stat="identity", fill="light green") +
coord_flip()
